/**
 * =====================================================
 * app.js
 * =====================================================
 * Frontend WebRTC para pruebas del asistente.
 * - Captura audio del micrÃ³fono
 * - Conecta con OpenAI Realtime (vÃ­a tu backend /session)
 * - EnvÃ­a eventos por DataChannel para que el asistente HABLE
 * =====================================================
 */

import { VOICE_CONFIG } from "./voice-config.js";
import { getGreetingByTime } from "./utils/greeting.js";

console.log("app.js cargado");

const startBtn = document.getElementById("startBtn");
const stopBtn = document.getElementById("stopBtn");
const statusEl = document.getElementById("status");
const logEl = document.getElementById("log");

let pc;
let dc;
let localStream;
let remoteAudio;

function log(msg) {
  const line = `[${new Date().toLocaleTimeString()}] ${msg}`;
  logEl.textContent += line + "\n";
  logEl.scrollTop = logEl.scrollHeight;
  console.log(line);
}

function sendEvent(obj) {
  if (!dc || dc.readyState !== "open") return;
  dc.send(JSON.stringify(obj));
}

async function startCall() {
  try {
    startBtn.disabled = true;
    stopBtn.disabled = false;
    statusEl.textContent = "Conectandoâ€¦";

    log("ðŸ“ž Llamar pulsado");

    // 1) PeerConnection
    pc = new RTCPeerConnection();

    // 2) Audio remoto (IMPORTANTE: play() tras gesto del usuario)
    remoteAudio = document.createElement("audio");
    remoteAudio.autoplay = true;
    remoteAudio.playsInline = true;
    remoteAudio.muted = false;
    remoteAudio.volume = 1;
    document.body.appendChild(remoteAudio);

    pc.ontrack = async (e) => {
      log("ðŸ”Š Audio remoto recibido (track)");
      remoteAudio.srcObject = e.streams[0];

      // Forzar reproducciÃ³n (algunos navegadores lo exigen)
      try {
        await remoteAudio.play();
        log("âœ… remoteAudio.play() OK");
      } catch (err) {
        log("âš ï¸ remoteAudio.play() bloqueado: " + (err?.message || err));
      }
    };

    // 3) MicrÃ³fono
    localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    localStream.getTracks().forEach((t) => pc.addTrack(t, localStream));
    log("ðŸŽ¤ MicrÃ³fono capturado");

    // 4) DataChannel
    dc = pc.createDataChannel("oai-events");
    dc.onopen = () => {
      log("ðŸŸ¢ DataChannel abierto");

      // Construimos prompt + saludo
      const greeting = getGreetingByTime();
      const systemPrompt = VOICE_CONFIG.buildSystemPrompt({ greeting });

      // A) Actualiza la sesiÃ³n (instrucciones + modalidades)
      sendEvent({
        type: "session.update",
        session: {
          instructions: systemPrompt,
          modalities: ["audio", "text"],
        },
      });

      // B) Forzar que hable primero (esto es CLAVE)
      sendEvent({
        type: "conversation.item.create",
        item: {
          type: "message",
          role: "user",
          content: [
            {
              type: "input_text",
              text:
                `Inicia la llamada saludando con: "${greeting}". ` +
                `DespuÃ©s pregunta en una sola frase: "Â¿En quÃ© puedo ayudarte?" y espera.`,
            },
          ],
        },
      });

      // C) Pide una respuesta en AUDIO
      sendEvent({
        type: "response.create",
        response: {
          modalities: ["audio", "text"],
        },
      });

      log("âž¡ï¸ Eventos enviados: session.update + greeting + response.create");
    };

    dc.onmessage = (event) => {
      // Ãštil para debug: ver eventos del modelo
      try {
        const data = JSON.parse(event.data);
        if (data?.type) {
          log(`ðŸ“© Event: ${data.type}`);
        }
      } catch {
        // ignore
      }
    };

    // 5) SDP Offer -> backend /session -> SDP Answer
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);

    log("ðŸ“¡ Enviando SDP a /sessionâ€¦");
    const sdpRes = await fetch("/session", {
      method: "POST",
      headers: { "Content-Type": "application/sdp" },
      body: offer.sdp,
    });

    if (!sdpRes.ok) {
      const err = await sdpRes.text();
      throw new Error("Error /session: " + err);
    }

    const answerSdp = await sdpRes.text();
    await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

    statusEl.textContent = "En llamadaâ€¦";
    log("âœ… Llamada establecida");
  } catch (e) {
    log("âŒ Error: " + (e?.message || e));
    statusEl.textContent = "Error";
    stopCall();
  }
}

function stopCall() {
  log("ðŸ›‘ Colgar pulsado");

  startBtn.disabled = false;
  stopBtn.disabled = true;

  try {
    dc?.close();
  } catch {}
  try {
    pc?.close();
  } catch {}

  localStream?.getTracks().forEach((t) => t.stop());

  if (remoteAudio) {
    remoteAudio.srcObject = null;
    remoteAudio.remove();
  }

  dc = null;
  pc = null;
  localStream = null;
  remoteAudio = null;

  statusEl.textContent = "Listo.";
  log("ðŸ”´ Llamada finalizada");
}

startBtn.onclick = startCall;
stopBtn.onclick = stopCall;
